{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies**"
      ],
      "metadata": {
        "id": "wwBRZ3AFFRA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "!pip install torch torchvision\n",
        "!pip install onnx\n",
        "!pip install numpy\n",
        "!pip install onnxruntime\n",
        "!pip install opencv-python"
      ],
      "metadata": {
        "cellView": "code",
        "id": "6dzwPhEvWHD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° (‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏û‡∏¥‡πà‡∏° DSPPF, C2fEMA, EMA) ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .pt ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏Ñ‡∏•‡∏≤‡∏™‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ runtime ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ reconstruct network graph ‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á**"
      ],
      "metadata": {
        "id": "_QmRgBnOHoJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) IMPORT CUSTOM MODULES\n",
        "‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç line 5: path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á project_root\n",
        "\n",
        "*   sys.path.append(\"D:/DCAS_project\")   # Windows\n",
        "*   sys.path.append(\"/home/user/DCAS_project\")  # Linux\n",
        "\n",
        "line 7 ‡∏Ñ‡∏∑‡∏≠ module ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô custom yolo ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ import"
      ],
      "metadata": {
        "id": "XV8oE6beK5yH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 1) ADD PROJECT ROOT TO PYTHON PATH\n",
        "# =====================================================\n",
        "import sys\n",
        "sys.path.append(\".\")   # ‡∏´‡∏£‡∏∑‡∏≠ path ‡πÄ‡∏ï‡πá‡∏°‡∏Ç‡∏≠‡∏á project_root"
      ],
      "metadata": {
        "id": "vIRxnuqDMkAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Register Custom Layers ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å\n",
        "\n",
        "Custom module ‡∏Ç‡∏≠‡∏á DCAS_EMAdp ‡∏°‡∏µ\n",
        "\n",
        "*   DSPPF\n",
        "*   C2fEMAdp\n",
        "*   EMAdp\n",
        "\n",
        "‡∏à‡∏∂‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ import ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤\n",
        "\n"
      ],
      "metadata": {
        "id": "aUoFiMfpK3a7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 2) IMPORT CUSTOM MODULES FROM ultralytics.nn\n",
        "# =====================================================\n",
        "from ultralytics.nn.modules import DSPPF, C2fEMA, EMA"
      ],
      "metadata": {
        "id": "hNaRJWkLMh9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Register custom layers ‡πÉ‡∏´‡πâ runtime ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å"
      ],
      "metadata": {
        "id": "O1TyUjjxLl5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 3) REGISTER CUSTOM LAYERS INTO ULTRALYTICS\n",
        "# =====================================================\n",
        "import ultralytics.nn.modules as um\n",
        "\n",
        "um.DSPPF = DSPPF\n",
        "um.C2fEMA = C2fEMA\n",
        "um.EMA = EMA"
      ],
      "metadata": {
        "id": "i3o6QsxqMfy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏ß‡πâ"
      ],
      "metadata": {
        "id": "xoAGdc5SMO99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 4) LOAD MODEL\n",
        "# =====================================================\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"best.pt\")   # ‡∏´‡∏£‡∏∑‡∏≠ path ‡πÄ‡∏ï‡πá‡∏°"
      ],
      "metadata": {
        "id": "Ah-V3pgpMc4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) Export ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡πá‡∏ô ONNX"
      ],
      "metadata": {
        "id": "XI7rwy5LMUAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# 5) EXPORT TO ONNX\n",
        "# =====================================================\n",
        "model.export(format=\"onnx\", imgsz=640, opset=12)\n",
        "\n",
        "print(\"EXPORT DONE\")"
      ],
      "metadata": {
        "id": "CQq03l1IMbFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£ import ‡∏à‡∏≤‡∏Å yolo26 ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô onnx ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"
      ],
      "metadata": {
        "id": "xkiOXJ9-NenA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLO26 model\n",
        "model = YOLO(\"yolo26n.pt\")\n",
        "\n",
        "# Export the model to ONNX format\n",
        "model.export(format=\"onnx\")  # creates 'yolo26n.onnx'\n",
        "\n",
        "# Load the exported ONNX model\n",
        "onnx_model = YOLO(\"yolo26n.onnx\")\n",
        "\n",
        "# Run inference\n",
        "results = onnx_model(\"https://ultralytics.com/images/bus.jpg\")\n",
        "\n",
        "annotated_image = results[0].plot()\n",
        "\n",
        "# save img\n",
        "cv2.imwrite(\"yolo26_result.jpg\", annotated_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKOTgOpgpdTb",
        "outputId": "c16b762d-b57f-4db7-c6ad-47697d1ed926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.4.14 üöÄ Python-3.12.12 torch-2.10.0+cpu CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "YOLO26n summary (fused): 122 layers, 2,408,932 parameters, 0 gradients, 5.4 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo26n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.3 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 22...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.85...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.8s, saved as 'yolo26n.onnx' (9.5 MB)\n",
            "\n",
            "Export complete (2.4s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolo26n.onnx imgsz=640 \n",
            "Validate:        yolo val task=detect model=yolo26n.onnx imgsz=640 data=/home/lq/codes/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "WARNING ‚ö†Ô∏è Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
            "Loading yolo26n.onnx for ONNX Runtime inference...\n",
            "Using ONNX Runtime 1.24.2 with CPUExecutionProvider\n",
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/bus.jpg: 640x640 4 persons, 1 bus, 155.7ms\n",
            "Speed: 3.5ms preprocess, 155.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£ ‡∏ô‡∏≥ weight best.pt ‡∏Ç‡∏≠‡∏á DCAS_EMAdp ‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô onnx ‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"
      ],
      "metadata": {
        "id": "OZZf6028Okq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "# Load the exported ONNX model\n",
        "onnx_model = YOLO(\"/content/best.onnx\")\n",
        "\n",
        "# Run inference\n",
        "results = onnx_model(\"/content/2024_11_25_15_03_33_exp_5_000000_NAVSTAR38USA126_flipH_blur.png\")\n",
        "# save img\n",
        "annotated_image = results[0].plot()\n",
        "cv2.imwrite(\"DCAS_EMAdp_result.jpg\", annotated_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlnNP28up1QK",
        "outputId": "fcf5cdb7-be73-4b58-e436-49cfb8b45ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ‚ö†Ô∏è Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
            "Loading /content/best.onnx for ONNX Runtime inference...\n",
            "Using ONNX Runtime 1.24.2 with CPUExecutionProvider\n",
            "\n",
            "image 1/1 /content/2024_11_25_15_03_33_exp_5_000000_NAVSTAR38USA126_flipH_blur.png: 640x640 1 object, 475.4ms\n",
            "Speed: 4.3ms preprocess, 475.4ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}